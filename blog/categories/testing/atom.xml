<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Testing | Art.sy Engineering]]></title>
  <link href="http://artsy.github.com/blog/categories/testing/atom.xml" rel="self"/>
  <link href="http://artsy.github.com/"/>
  <updated>2012-05-29T06:54:00-04:00</updated>
  <id>http://artsy.github.com/</id>
  <author>
    <name><![CDATA[Art.sy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Jenkins for Ruby and Ruby-on-Rails Teams]]></title>
    <link href="http://artsy.github.com/blog/2012/05/27/using-jenkins-for-ruby-and-ruby-on-rails-teams/"/>
    <updated>2012-05-27T08:15:00-04:00</updated>
    <id>http://artsy.github.com/blog/2012/05/27/using-jenkins-for-ruby-and-ruby-on-rails-teams</id>
    <content type="html"><![CDATA[<p>The <a href="http://jenkins-ci.org">Jenkins CI</a> project has grown tremendously in the past few months. There're now hundreds of plugins and an amazing engaged community. Art.sy is a happy user and proud contributor to this effort with the essential <a href="https://wiki.jenkins-ci.org/display/JENKINS/AnsiColor+Plugin">jenkins-ansicolor plugin</a>, eliminating boring console output since 2011.</p>

<p>We are a continuous integration, deployment and devops shop and have been using Jenkins for over a year now. We've shared our experience at the <a href="http://www.cloudbees.com/juc2012.cb">Jenkins User Conference 2012</a> in <a href="http://www.slideshare.net/dblockdotorg/graduating-to-jenkins-ci-for-rubyonrails-teams">a presentation</a>. This blog post is an overview of how to get started with Jenkins for Ruby(-on-Rails) teams.</p>

<p><img src="/images/2012-05-27-using-jenkins-for-ruby-on-rails-teams/jenkins.png" title="[Art.sy Jenkins CI]" ></p>

<!-- more -->


<p>When Art.sy had only three engineers, we hesitated to deploy Jenkins. The CI server was written in Java (i.e. wasn't written in Ruby). We feared introducing excessive infrastructure too early. In retrospect, we were not in the business of building CI infrastructure, so not using Jenkins was a mistake. Since we adopted it, Jenkins has been operating painlessly and scaled nicely as our needs continued to grow.</p>

<p>Today, we run a single virtual server on <a href="http://www.linode.com">Linode</a> as our master Jenkins and have 8 Linode slaves. These are all $19 per month plans. Our usage is variable: few builds in the middle of the night and a very high number of builds during the day, so we're planning on trying to build a Jenkins-slave on-demand system on AWS eventually.</p>

<p>Setting up a Jenkins master is straightforward.</p>

<p><code>bash
useradd -m jenkins -p [password] -s /bin/bash
addgroup jenkins sudo
wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key add –
sudo sh -c 'echo deb http://pkg.jenkins-ci.org/debian binary/ &gt; /etc/apt/sources.list.d/jenkins.list'
sudo aptitude update
sudo aptitude install jenkins
</code></p>

<p>We change Jenkins port in <code>/etc/default/jenkins</code>, add the machine to DNS and update the Jenkins URL to an externally visible one in the "Manage Jenkins", "Configure System" menu. We enable and use "Matrix-Based Security" with a single user that all developers share and give the user permission to do everything in the same UI. Finally, we configure the Git Plugin with a global username and e-mail from our shared IT account that has Github access, setup a Github Web Hook and SMTP E-Mail notifications. Restarting Jenkins from the command line with <code>sudo service jenkins restart</code> completes the initial setup.</p>

<p>It's also a good idea to setup Jenkins configuration backup with <a href="https://wiki.jenkins-ci.org/display/JENKINS/thinBackup">thinBackup</a>, install <a href="http://wiki.jenkins-ci.org/display/JENKINS/AnsiColor+Plugin">AnsiColor</a> and, of course, enable <a href="http://wiki.hudson-ci.org/display/HUDSON/ChuckNorris+Plugin">Chuck Norris</a>.</p>

<p>A typical Ruby development environment includes <a href="https://rvm.io/">RVM</a>, a working GIT client and a Github SSH key. We install these under our <code>jenkins</code> user manually on the first slave Linode and then clone slaves when we need more. RVM setup includes entries in <code>~/.bash_profile</code>, so a Jenkins job for a Ruby project can load that file and execute commands, including <code>rake</code>.</p>

<p>``` bash</p>

<h1>!/bin/bash</h1>

<p>source ~/.bash_profile
rvm use 1.9.2
gem install bundler
bundle install
bundle exec rake
```</p>

<p>Our default Ruby project Rake task is <code>test:ci</code>. We run Jasmine and Capybara tests using a real browser, so we need to redirect all visible output to an X-Windows Virtual Frame Buffer (<a href="http://www.xfree86.org/4.0.1/Xvfb.1.html">XVFB</a>). This can be done by setting an <code>ENV</code> variable inside a Rake task. Our test target also <a href="http://artsy.github.com/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/">organizes our tests in suites</a>.</p>

<p><code>ruby
namespace :test do
  task :specs, [ :display ] =&gt; :environment do |t, args|
   ENV['DISPLAY'] = args[:display] if args[:display]
   Rake::Task['spec:suite:all'].invoke
  end
      
  task :jasmine, [ :display ] =&gt; :environment do |t, args|
    ENV['DISPLAY'] = args[:display] if args[:display]
    system!("bundle exec rake jasmine:ci")
  end
    
  task :all, [ :display ] =&gt; :environment do |t, args|
    Rake::Task['assets'].invoke
    Rake::Task['test:jasmine'].invoke(args[:display])
    Rake::Task['test:specs'].invoke(args[:display])
  end
      
  task :ci do
    Rake::Task['test:all'].invoke(":99")
  end
      
end
</code></p>

<p>A successful CI test run will trigger a deployment to a staging environment on Heroku.</p>

<p>``` ruby
namespace :deploy do
  task :staging => :environment do
    system!("bundle exec heroku maintenance:on --app=app-staging")</p>

<pre><code>system!("git push git@heroku.com:app-staging.git origin/staging:master")    
system!("bundle exec heroku maintenance:off --app=app-staging")
</code></pre>

<p>  end
end
```</p>

<p>You'll notice that we execute system commands with <code>system!</code>. Unlike the usual <code>system</code> method, our wrapper raises an exception when a command returns a non-zero error code to abort execution.</p>

<p><code>ruby
def system!(cmdline)
  logger.info("[#{Time.now}] #{cmdline}")
  rc = system(cmdline)
  "failed with exit code #{$?.exitstatus}" if (rc.nil? || ! rc || $?.exitstatus != 0)
end
</code></p>

<p>Our production deployment task is also a Jenkins job.</p>

<p>``` ruby
namespace :deploy do
  task :production => :environment do</p>

<pre><code>system!("git push git@heroku.com:app-production.git origin/production:master")
</code></pre>

<p>  end
end
```</p>

<p>We don't want any downtime on our production environment, so we don't turn Heroku maintance on. Our staging deployment task also includes copying production data to staging, so we chose to enable maintenance to avoid people hitting the test environment while it's being built and may be in a half-baked state.</p>

<p>Finally, we also run production daily CRON-like tasks via Jenkins. It gives us email notifications, console output and the ability to manually trigger them. Centralizing operations in the same environment as CI creates truly continuous integration, deployment and operations.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Organize Over 3000 RSpec Specs and Retry Test Failures]]></title>
    <link href="http://artsy.github.com/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/"/>
    <updated>2012-05-15T12:00:00-04:00</updated>
    <id>http://artsy.github.com/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures</id>
    <content type="html"><![CDATA[<p>Having over three thousand RSpec tests in a single project has become difficult to manage. We chose to organize these into suites, somewhat mimicking our directory structure. And while we succeeded at making our Capybara integration tests more reliable (see <a href="/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/">Reliably Testing Asynchronous UI with RSpec and Capybara</a>), they continue relying on finicky timeouts. To avoid too many false positives we've put together a system to retry failed tests. We know that a spec that fails twice in a row is definitely not a fluke!</p>

<p>Create a new Rake file in <code>lib/tasks/test_suites.rake</code> and declare an array of test suites.</p>

<p>``` ruby lib/tasks/test_suites.rake
  SPEC_SUITES = [</p>

<pre><code>{ :id =&gt; :models, :pattern =&gt; "spec/models/**/*_spec.rb" },
{ :id =&gt; :controllers, :pattern =&gt; "spec/controllers/**/*_spec.rb" },
{ :id =&gt; :views, :pattern =&gt; "spec/views/**/*_spec.rb" }
</code></pre>

<p>  ]
```</p>

<!-- more -->


<p><code>RSpec::Core</code> contains a module called <code>RakeTask</code> that will programmatically create Rake tasks for you.</p>

<p>``` ruby lib/tasks/test_suites.rake
require 'rspec/core/rake_task'</p>

<p>namespace :test
  namespace :suite</p>

<pre><code>RSpec::Core::RakeTask.new("#{suite[:id]}:run") do |t|
  t.pattern = suite[:pattern]
  t.verbose = false
  t.fail_on_error = false
end
</code></pre>

<p>  end
end
```</p>

<p>Run <code>rake -T</code> to ensure that the suites have been generated. To execute a suite, run <code>rake test:suite:models:run</code>. Having a test suite will help you separate spec failures and enables other organizations than by directory, potentially allowing you to tag tests across multiple suites.</p>

<p><code>bash
rake spec:suite:models:run
rake spec:suite:controllers:run
rake spec:suite:views:run
</code></p>

<p>Retrying failed specs has been a long requested feature in RSpec (see <a href="https://github.com/rspec/rspec-core/issues/456">#456</a>). A viable approach has been finally implemented by <a href="https://github.com/antifun">Matt Mitchell</a> in <a href="https://github.com/rspec/rspec-core/pull/596">#596</a>. There're a few issues with that pull request, but two pieces have already been merged that make retrying specs feasible outside of RSpec.</p>

<ul>
<li><a href="https://github.com/rspec/rspec-core/pull/610">#610</a>:
A fix for incorrect parsing input files specified via <code>-O</code>.</li>
<li><a href="https://github.com/rspec/rspec-core/pull/614">#614</a>:
A fix for making the <code>-e</code> option cumulative, so that one can pass multiple example names to run.</li>
</ul>


<p>Both will appear in the 2.11.0 version of RSpec, in the meantime you have to point your <code>rspec-core</code> dependency to the latest version on Github.</p>

<p><code>ruby Gemfile
"rspec-core", :git =&gt; "https://github.com/rspec/rspec-core.git"
</code></p>

<p>Don't forget to run <code>bundle update rspec-core</code>.</p>

<p>The strategy to retry failed specs is to output a file that contains a list of failed ones and to feed that file back to RSpec. The former can be accomplished with a custom logger. Create <code>spec/support/formatters/failures_formatter.rb</code>.</p>

<p>``` ruby spec/support/formatters/failures_formatter.rb
require 'rspec/core/formatters/base_formatter'</p>

<p>module RSpec
  module Core</p>

<pre><code>module Formatters
  class FailuresFormatter &lt; BaseFormatter

    # create a file called rspec.failures with a list of failed examples
    def dump_failures
      return if failed_examples.empty?
      f = File.new("rspec.failures", "w+")
      failed_examples.each do |example|
        f.puts retry_command(example)
      end
      f.close
    end

    def retry_command(example)
      example_name = example.full_description.gsub("\"", "\\\"")
      "-e \"#{example_name}\""
    end

  end
end
</code></pre>

<p>  end
end
```</p>

<p>In order to use the formatter, we must tell RSpec to <code>require</code> it with <code>--require</code> and to use it with <code>--format</code>. We don't want to lose our settings in <code>.rspec</code> either - all these options can be combined in the Rake task.</p>

<p>``` ruby lib/tasks/test_suites.rake
RSpec::Core::RakeTask.new("#{suite[:id]}:run") do |t|
  t.pattern = suite[:pattern]
  t.verbose = false
  t.fail_on_error = false
  t.spec_opts = [</p>

<pre><code>"--require", "#{Rails.root}/spec/support/formatters/failures_formatter.rb",
"--format", "RSpec::Core::Formatters::FailuresFormatter",
File.read(File.join(Rails.root, ".rspec")).split(/\n+/).map { |l| l.shellsplit }
</code></pre>

<p>  ].flatten
end
```</p>

<p>Once a file is generated, we can feed it back to RSpec in another task, called <code>suite:suite[:id]:retry</code>.</p>

<p>``` ruby lib/tasks/test_suites.rake
RSpec::Core::RakeTask.new("#{suite[:id]}:retry") do |t|
  t.pattern = suite[:pattern]
  t.verbose = false
  t.fail_on_error = false
  t.spec_opts = [</p>

<pre><code>"-O", File.join(Rails.root, 'rspec.failures'),
File.read(File.join(Rails.root, '.rspec')).split(/\n+/).map { |l| l.shellsplit }
</code></pre>

<p>  ].flatten
end
```</p>

<p>Finally, lets combine the two tasks and invoke <code>retry</code> when the <code>run</code> task fails.</p>

<p>``` ruby lib/tasks/test_suites.rake
task "#{suite[:id]}" do
  rspec_failures = File.join(Rails.root, 'rspec.failures')
  FileUtils.rm_f rspec_failures
  Rake::Task["spec:suite:#{suite[:id]}:run"].execute
  unless $?.success?</p>

<pre><code>puts "[#{Time.now}] Failed, retrying #{File.read(rspec_failures).split(/\n+/).count} failure(s) in spec:suite:#{suite[:id]} ..."
Rake::Task["spec:suite:#{suite[:id]}:retry"].execute
</code></pre>

<p>  end
end
```</p>

<p>A complete version of our <code>test_suites.rake</code>, including a <code>spec:suite:all</code> task that executes all specs can be found <a href="https://gist.github.com/2597305">in this gist</a>. Our Jenkins CI runs <code>rake spec:suite:all</code>, with a much improved weather report since we started using this system.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reliably Testing Asynchronous UI w/ RSpec and Capybara]]></title>
    <link href="http://artsy.github.com/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/"/>
    <updated>2012-02-03T11:45:00-05:00</updated>
    <id>http://artsy.github.com/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara</id>
    <content type="html"><![CDATA[<p>tl;dr - You can write 632 rock solid UI tests with Capybara and RSpec, too.</p>

<p><img src="/images/2012-02-03-reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/jenkins-ci.png" title="[Miami Weather in NYC]" ></p>

<p>We have exactly 231 integration tests and 401 view tests out of a total of 3086 in our core application today. This adds up to 632 tests that exercise UI. The vast majority use <a href="http://rspec.info/">RSpec</a> with <a href="https://github.com/jnicklas/capybara">Capybara</a> and <a href="http://seleniumhq.org/">Selenium</a>. This means that every time the suite runs we set up real data in a local MongoDB and use a real browser to hit a fully running local application, 632 times. The suite currently takes 45 minutes to run headless on a slow Linode, UI tests taking more than half the time.</p>

<p>While the site is in private beta (request your invite <a href="http://art.sy/request_invite">here</a>), you can get a glimpse of the complexity of the UI from the <a href="http://art.sy">splash page</a>. It's a rich client-side Javascript application that talks to an API. You can open your browser's developer tools and watch a combination of API calls and many asynchronous events.</p>

<p>Keeping the UI tests reliable is notoriously difficult. For the longest time we felt depressed under the Pacific Northwest -like weather of our Jenkins CI and blamed every possible combination of code and infrastructure for the many intermittent failures. We've gone on sprees of marking many such tests "pending" too.</p>

<p>We've learned a lot and stabilized our test suite. This is how we do UI testing.</p>

<!-- more -->


<h2>An Asynchronous Application</h2>

<p>The splash page on <a href="http://art.sy">art.sy</a> is a <a href="http://documentcloud.github.com/backbone/">Backbone.js</a> application where views fade in and out depending on user actions. It also implements a responsive layout because some elements cannot render on mobile devices or shouldn't depending on the size of your browser.</p>

<p>The application is initialized in a usual Backbone way.</p>

<p>``` coffeescript
window.Splash =
  Views: {}
  Routers: {}
  Models: {}
  initialize: -></p>

<pre><code>contentWindow = new @Models.ContentWindow()
@router = new @Routers.Client contentWindow
new @Views.Responsive contentWindow
</code></pre>

<p>```</p>

<p>From here, everything is asynchronous. The router will wire up the events and the different views that make up the page will render themselves.</p>

<h2>Testing a Login Form</h2>

<p>When a user clicks on a "Log In" link, he sees the <code>Splash.Views.Login</code> Backbone view. There's no page reload or server roundtrip: the current view is swapped out by the Backbone view coming in. Some CSS animates the transition.</p>

<p>``` coffeescript</p>

<p>class Splash.Routers.Client extends Backbone.Router</p>

<p>  routes:</p>

<pre><code>'log_in' : 'log_in'
</code></pre>

<p>  log_in: -></p>

<pre><code>Splash.login = new Splash.Views.Login()
@navigate 'log_in'
</code></pre>

<p>```</p>

<p>The log-in view has two input fields: an e-mail address and password. We can write a Capybara test that enters valid values and ensures that the user logged in by checking for a specific header.</p>

<p>``` ruby
require 'spec_helper'</p>

<p>feature "Log In" do
  context "using a browser", :js => true do</p>

<pre><code>scenario "allows a user to login" do
  user = Fabricate(:user)
  visit "/"
  click_link "log_in"
  fill_in "user[email]", :with =&gt; user.email
  fill_in "user[password]", :with =&gt; user.password
  click_button "sign in"
  find("h1", :visible =&gt; true).text.should == "Login Successful"
end
</code></pre>

<p>  end
end
```</p>

<p>This test works well with Capybara, because it tries to wait for elements to appear on the page. For example, when you use <code>fill_in</code> it attempts to locate an element with the <code>user[email]</code> id, several times, until it times out or until the element is on the page.</p>

<h2>Waiting for Explicit Events</h2>

<p>The above test is "reliable" within some limits. It works as long as all the necessary asynchronous events run within a timeout period. But what if they don't? What if the test hardware is taking a break from flushing to disk? Or waiting on Google Analytics when the network cable is unplugged, which shouldn't affect the outcome of the test? These external issues make this code very brittle, so everyone keeps increasing the default timeout values.</p>

<p>A winning strategy to avoid this is to introduce explicit wait controls inside the tests. These wait <code>Capybara.default_wait_time</code> for a true result and no longer force you to know which method in Capybara waits for a timeout and which doesn't. It effectively breaks up a single wait into multiple waits.</p>

<p>Consider a widget that needs to be saved by making a postback.</p>

<p>``` coffeescript
@$el.removeClass("saved").addClass('saving')
@widget.save
  success: =></p>

<pre><code>@$el.removeClass("saving").addClass("saved")
</code></pre>

<p>```</p>

<p>When the widget is saved, its element will get a <code>.saved</code> CSS class. The test can wait for it.</p>

<p><code>ruby
it "saves the widget" do
  widget_count = Widget.count
  find("save").click
  wait_until { find(".saved", visible: true) }
  Widget.count.should == widget_count + 1
end
</code></p>

<h2>There's Just Too Much Going On</h2>

<p>Sometimes, waiting on explicit events is just not practical. You may have many AJAX requests going on at the same time and after those are done, you may still be executing JavaScript that modifies the DOM in meaningful ways. Lets attempt to answer the following two questions:</p>

<ul>
<li>How can we wait on all remaining AJAX requests to finish?</li>
<li>How can we wait on all remaining DOM events to finish?</li>
</ul>


<h2>Remaining AJAX Requests</h2>

<p>If you're using jQuery, you can test the number of active connections to a server. The number is zero when all pending AJAX requests have finished. This was an original idea from <a href="http://pivotallabs.com/users/mgehard/blog/articles/1671-waiting-for-jquery-ajax-calls-to-finish-in-cucumber">Pivotal</a>.</p>

<p>``` ruby spec/support/wait_for_ajax_helper.rb
def wait_for_ajax(timeout = Capybara.default_wait_time)
  page.wait_until(timeout) do</p>

<pre><code>page.evaluate_script 'jQuery.active == 0'
</code></pre>

<p>  end
end
```</p>

<h2>Remaining DOM Events</h2>

<p>This one is a bit tricker. We can leverage the fact that JavaScript engines are updating the UI on a single thread. If you defer an action it will execute after everything else that has been deferred before it. Therefore we can queue an addition of an empty DIV with a new id and finally wait for it. By using a unique ID we allow the waits to stack up nicely in a single spec.</p>

<p>``` ruby spec/support/wait_for_dom_helper_.rb
def wait_for_dom(timeout = Capybara.default_wait_time)
  uuid = SecureRandom.uuid
  page.find("body")
  page.evaluate_script &lt;&lt;-EOS</p>

<pre><code>_.defer(function() {
  $('body').append("&lt;div id='#{uuid}'&gt;&lt;/div&gt;");
});
</code></pre>

<p>  EOS
  page.find("##{uuid}")
end
```</p>

<p>We do have to make sure that the body element is loaded, first. This allows a <code>wait_for_dom</code> right after we navigate to a page that executes AJAX queries on load.</p>

<h2>Combining Techniques</h2>

<p>With enough attention we were able to explain and fix most spec failures. When implementing Capybara tests we favor explicit waits and use the combination of the two wait functions above when we just want to generically make sure that everything on the page has loaded and is ready for more action.</p>

<p>Finally, integration tests are essential for continuous deployment. They are very much worth the extra development effort.</p>
]]></content>
  </entry>
  
</feed>
