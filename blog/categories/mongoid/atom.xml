<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mongoid | Art.sy Engineering]]></title>
  <link href="http://artsy.github.com/blog/categories/mongoid/atom.xml" rel="self"/>
  <link href="http://artsy.github.com/"/>
  <updated>2013-02-02T15:15:30-05:00</updated>
  <id>http://artsy.github.com/</id>
  <author>
    <name><![CDATA[Art.sy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Create MongoDB Command-Lines from Mongoid Configuration]]></title>
    <link href="http://artsy.github.com/blog/2013/01/31/create-mongodb-command-lines-with-mongo/"/>
    <updated>2013-01-31T21:21:00-05:00</updated>
    <id>http://artsy.github.com/blog/2013/01/31/create-mongodb-command-lines-with-mongo</id>
    <content type="html"><![CDATA[<p>We use MongoDB as our primary store and have built a healthy amount of automation around various database instances and operational environments. For example, we backup databases to S3 using <code>mongodump</code>, mirror data between instances with <code>mongorestore</code> and often need to open a MongoDB shell with <code>mongo</code> to examine data at the lowest level.</p>

<p>Generating MongoDB command-lines is tedious and error-prone. Introducing a new gem called <a href="https://github.com/dblock/mongoid-shell">mongoid-shell</a> to help with this. The library can generate command-lines for various MongoDB shell tools from your Mongoid configuration.</p>

<p>For example, connect to your production MongoDB instance from a <code>db:production:shell</code> Rake task.</p>

<p>```ruby
namespace :db
  namespace :production</p>

<pre><code>task :shell
  Mongoid.load! "mongoid.yml", :production
  system Mongoid::Shell::Commands::Mongo.new.to_s
end
</code></pre>

<p>  end
end
```</p>

<!-- more -->


<p>Commands can be created for the current default session or you can pass a session as an argument to a new command.</p>

<p>```ruby</p>

<h1>will use Mongoid.default_session</h1>

<p>Mongoid::Shell::Commands::Mongodump.new</p>

<h1>use a hand-crafted session</h1>

<p>s = Moped::Session.new([ "127.0.0.1:27017" ])
Mongoid::Shell::Commands::Mongodump.new(session: s)
```</p>

<p>Commands accept parameters. Here's how to backup <code>my_database</code> to <code>/tmp/db_backup</code>.</p>

<p>```ruby
out = File.join(Dir.tmpdir, 'db_backup')
db = 'my_database'
dump = Mongoid::Shell::Commands::Mongodump.new(db: db, out: out)</p>

<h1>mongodump --db my_database --out /tmp/db_backup</h1>

<p>system dump.to_s
```</p>

<p>The mongoid-shell gem currently supports <code>mongo</code>, <code>mongodump</code>, <code>mongorestore</code> and <code>mongostat</code> and various MongoDB configurations, including replica-sets.</p>

<p>Please note that we don't recommend you store passwords for production environments in your <code>mongoid.yml</code>. At Artsy, we set all sensitive values directly on our Heroku instances with <code>heroku config:add</code> and use <a href="https://github.com/dblock/heroku-commander">heroku-commander</a> to retrieve these settings in rake. We also have a bit of convention in our application name, such as "app-staging" and "app-production".</p>

<p>Here's a complete Rake task that dynamically fetches Heroku configuration and opens a MongoDB shell on a production or staging environment.</p>

<p>```ruby
namespace :db do
  [ :staging, :production ].each do |env|</p>

<pre><code>namespace env do
  task :shell do
    app = "myapp-#{env}"
    config = Heroku::Commander.new(app: app).config
    config.each_pair do |k, v|
      ENV[k] = v
    end
    mongoid_yml = File.join(Rails.root, "config/mongoid.yml")
    Mongoid.load! mongoid_yml, env
    system Mongoid::Shell::Commands::Mongo.new.to_s
  end
end
</code></pre>

<p>  end
end
```</p>

<p>Run <code>rake db:staging:shell</code> or <code>rake db:production:shell</code>, which works as long as you have access to the Heroku app itself. A bonus feature is that the mongoid-shell gem will automatically connect to the primary node of a replica-set.</p>

<p>```
$ rake db:staging:shell
 mongo db:10007/app-staging --username user --password ************
 MongoDB shell version: 2.0.7
 connecting to: db:10007/app-staging</p>

<blockquote><p>```</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving Performance of Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.com/blog/2013/01/20/improving-performance-of-mongoid-cached-json/"/>
    <updated>2013-01-20T21:21:00-05:00</updated>
    <id>http://artsy.github.com/blog/2013/01/20/improving-performance-of-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Last year, we have open-sourced and made extensive use of two Ruby libraries in our API: <a href="https://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> and <a href="https://github.com/artsy/garner">garner</a>. Both transform the procedural nightmare of caching and JSON generation into a declarative and easily manageable DSL. It was worth the investment, since our service spends half of its time generating JSON and reading from and writing to Memcached.</p>

<p>Today we've released mongoid-cached-json 1.4 with two interesting performance improvements.</p>

<!-- more -->


<h2>Bulk Reference Resolving with a Local Cache</h2>

<p>Consider an array of database model instances, each with numerous references to other objects. It's typical to see such instances reference the same object: for example we have an <code>Artwork</code> that references an <code>Artist</code>. It's common to see multiple artworks reference the same artist in a collection. Retrieving the artist from cache every time it is referenced is clearly inefficient.</p>

<p><code>Mongoid::CachedJson</code> will now collect all JSON references, then resolve them after suppressing duplicates, in-place within the JSON tree. This significantly reduces the number of cache queries.</p>

<p>Note, that while this optimization reduces load on the Memcached servers, there's a cost of doing additional work after collecting the entire JSON in Ruby.</p>

<h2>Fetching Cache Data in Bulk</h2>

<p>Various cache stores, including Memcached, support bulk read operations. The <a href="https://github.com/mperham/dalli">Dalli</a> gem, which we use in production, exposes this via the <code>read_multi</code> method. With the bulk reference optimization above we now have the entire list of keys to query from cache, at once. <code>Mongoid::CachedJson</code> will always invoke <code>read_multi</code> where available, which significantly reduces the number of network roundtrips to the cache servers.</p>

<p>This is a good example of where declarative models and DSLs have tremendous advantages in enabling massive improvements across the board. Imagine making the <code>read_multi</code> optimization in hundreds of API endpoints!</p>

<h2>Benchmarks</h2>

<p>With the above optimizations the library does more work in order to make less roundtrips to Memcached over the network. Since the network is often the slowest part in any large scale system, the overall production performance should be better as long as we can obtain similar throughput in ideal network conditions on localhost. We've added some common case benchmarks in <a href="https://github.com/dblock/mongoid-cached-json/blob/master/spec/benchmark_spec.rb">spec/benchmark_spec.rb</a> and ran them against 1.2.3 and 1.4.0 to obtain <a href="https://gist.github.com/4583039">these results</a>. The overall performance gain averaged 14.6%, which is quite significant. With real world data in a production environment we're seeing 15-50% less time spent in Memcached, depending on the API.</p>

<h2>Links</h2>

<p>The concepts behind these improvements should be attributed to <a href="https://github.com/aaw">@aaw</a> and <a href="https://github.com/macreery">@macreery</a>. If you want to learn more about the above-mentioned libraries, check out the following links:</p>

<ul>
<li><a href="http://confreaks.com/videos/986-goruco2012-from-zero-to-api-cache-w-grape-mongodb-in-10-minutes">From Zero to API-Cache w/ Grape and MongoDB</a>, video recorded at GoRuCo</li>
<li><a href="/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/">Caching Model JSON with Mongoid-Cached-Json</a></li>
<li><a href="/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json/">Simplifying Model Level Versioning with Mongoid-Cched-Json</a></li>
<li><a href="/blog/2012/05/30/restful-api-caching-with-garner/">RESTful API Caching with Garner</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Friendly URLs with Mongoid::Slug]]></title>
    <link href="http://artsy.github.com/blog/2012/11/22/friendly-urls-with-mongoid-slug/"/>
    <updated>2012-11-22T21:21:00-05:00</updated>
    <id>http://artsy.github.com/blog/2012/11/22/friendly-urls-with-mongoid-slug</id>
    <content type="html"><![CDATA[<p>All Artsy URLs shared publicly are humanly readable. For example, you'll find all Barbara Kruger's works at <a href="http://artsy.net/artist/barbara-kruger">artsy.net/artist/barbara-kruger</a> and a post by Hyperallergic entitled "Superfluous Men Can't Get No Satisfaction" at <a href="http://artsy.net/hyperallergic/post/superfluous-men-cant-get-no-satisfaction">artsy.net/hyperallergic/post/superfluous-men-cant-get-no-satisfaction</a>. This is a lot prettier than having <code>id=42</code> in the browser's address and is a big improvement for SEO.</p>

<p><img src="http://artsy.github.com/images/2012-11-22-friendly-urls-with-mongoid-slug/barbara-kruger.png"></p>

<p>We construct these URLs with a gem called <a href="https://github.com/digitalplaywright/mongoid-slug">mongoid_slug</a>. Interesting implementation details under the cut.</p>

<!-- more -->


<h2>Mongoid-Slug Basics</h2>

<p>Include the gem in Gemfile.</p>

<p><code>ruby Gemfile
gem "mongoid_slug", "~&gt; 2.0.1"
</code></p>

<p>The basic functionality of mongoid-slug is achieved by adding the <code>Mongoid::Slug</code> a mixin and declaring a slug.</p>

<p>``` ruby post.rb
class Post
  include Mongoid::Document
  include Mongoid::Slug</p>

<p>  belongs_to :author, class_name: "User"</p>

<p>  field :title, type: String
  slug :title, history: true, scope: :author</p>

<p>  field :published, type: Boolean
end
```</p>

<p>This adds a <code>_slugs</code> field of type <code>Array</code> into the <code>Post</code> model. Every time the title of the post changes, a new slug is generated and, depending on the value of the <code>history</code> option, either replaces the existing slug or appends the new slug to the array of slugs. A database index ensures that these are unique: two posts of the same title will have different slugs, such as "post-1" and "post-2". Our example is also scoped to the author of the post.</p>

<p>You can now find this post by <code>_id</code> or <code>slug</code> with the same <code>find</code> method. And with <code>history: true</code>, you can find a document by any of its older slugs!</p>

<p>```</p>

<h1>find by ID</h1>

<p>user.posts.find("47cc67093475061e3d95369d")</p>

<h1>find by slug</h1>

<p>user.posts.find("superfluous-men-cant-get-no-satisfaction")
```</p>

<p>Mongoid-slug is smart enough to figure out whether you're querying by a <code>Moped::BSON::ObjectId</code> or a slug. Performance-wise the lookup by slug is cheap: mongoid_slug ensures an index on <code>_slugs</code>. This all works, of course, because MongoDB builds a B-tree index atop all elements in each <code>_slugs</code> array.</p>

<p>The <code>find</code> method will naturally respect Mongoid's <code>raise_not_found_error</code> option and either raise <code>Mongoid::Errors::DocumentNotFound</code> or return <code>nil</code> in the case the document cannot be found.</p>

<h2>Avoiding Too Many Slugs</h2>

<p>Users writing posts may want to edit them many times before they are published. This can potentially create a large number of unnecessary slugs. We've used a simple trick to generate slugs only after a post has been published by defaulting the slug of an unpublished post to its <code>_id</code>. Mongoid-slug will append <code>-1</code> to such slugs, so we monkey-patch <code>Mongoid::Slug::UniqueSlug</code> with the code in <a href="https://gist.github.com/4131766">this gist</a>. Special care must be taken not to destroy a slug of a post that has been published earlier, then unpublished.</p>

<p>``` ruby
slug :title, :published, scope: :author, history: true do |p|
  if p.published? || p.has_slug?</p>

<pre><code>p.title.to_url
</code></pre>

<p>  else</p>

<pre><code>p.id.to_s
</code></pre>

<p>  end
end</p>

<p>def has_slug?
  ! slug.blank? &amp;&amp; slug != id.to_s
end
```</p>

<p>The parameters to <code>slug</code> include all fields that may cause the slug to change. When a post is published by setting <code>published</code> to <code>true</code>, the slug will be re-generated with a call to <code>build_slug</code> as long as the <code>published</code> field is included in that list.</p>

<p>Please note an interesting discussion about allowing model ids in the <code>_slugs</code> <a href="https://github.com/digitalplaywright/mongoid-slug/pull/91">here</a>.</p>

<h2>Caching by Slug</h2>

<p>Because slugs can now change, but lookups by old slugs should hit the cache, caching by slug makes cache invalidation difficult. A two-layered cache that maps slugs to ids and then caches objects by id can solve this at the expense of an additional cache lookup. We have yet to implement this in <a href="https://github.com/artsy/garner">Garner</a>, see <a href="https://github.com/artsy/garner/issues/13">#13</a>.</p>

<h2>International Slugs</h2>

<p>We have a large international audience with names and posts in all kinds of languages. An escaped UTF-8 URL would be much worse than a BSON ObjectId. Fortunately, mongoid-slug uses <a href="https://github.com/rsl/stringex">stringex</a> under the hood. This gem defines <code>to_url</code> and rewrites special symbols and transliterates strings from many languages into English. Here're some examples of generated slugs.</p>

<p>``` ruby
"ITCZ 1 (21°17ʼ51.78”N / 89°35ʼ28.18”O / 26-04-08 / 09:00 am)".to_url</p>

<h1>=> itcz-1-21-degrees-17-51-dot-78-n-slash-89-degrees-35-28-dot-18-o-slash-26-04-08-slash-09-00-am</h1>

<p>"“水／火”系列 No.8".to_url</p>

<h1>=> "shui-slash-huo-xi-lie-no-dot-8"</h1>

<p>"трактат по теории этики".to_url</p>

<h1>=> "traktat-po-tieorii-etiki"</h1>

<p>```</p>

<p>Pretty amazing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simplifying Model-Level JSON Versioning with Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.com/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json/"/>
    <updated>2012-03-23T09:14:00-04:00</updated>
    <id>http://artsy.github.com/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Did you know that Netflix has hundreds of API versions, one for each device? Daniel Jacobson's <a href="http://www.slideshare.net/danieljacobson/techniques-for-scaling-the-netflix-api-qcon-sf">Techniques for Scaling the Netflix API</a> at QConSF 2011 explained why they chose this model. And while we don't all build distributed services that supply custom-tailored data to thousands of heterogeneous TVs and set-top boxes, we do have to pay close attention to API versioning from day one.</p>

<p>Versioning is hard. Your data models evolve, but you must maintain backward-compatibility for your public interfaces. While many strategies exist to deal with this problem, we'd like to propose one that requires very little programming effort and that is more declarative in nature.</p>

<p>At Artsy we use <a href="http://github.com/intridea/grape">Grape</a> and implement the "path" versioning strategy from the <a href="http://github.com/intridea/grape/tree/frontier">frontier</a> branch. Our initial v1 API is consumed by our own website and services and lives at <a href="https://artsyapi.com/api/v1">https://artsyapi.com/api/v1</a>. We've also prototyped v2 and by the time v1 is frozen, it should already be in production.</p>

<p>Grape takes care of version-based routing and has a system that lets you split version-based presentation of a model from the model implementation. I find that separation forcefully induced by unnecessary implementation complexity around wanting to return different JSON depending on the API version requested. What if implementing versioning in <code>as_json</code> were super simple?</p>

<p>Consider a Person model returned from a v1 API.</p>

<p>``` ruby
class API &lt; Grape::API
  prefix :api
  version :v1
  namespace :person</p>

<pre><code>get ":id"
  Person.find(params[:id]).as_json
end
</code></pre>

<p>  end
end
```</p>

<p>``` ruby
class Person
  include Mongoid::Document</p>

<p>  field :name</p>

<p>  def as_json</p>

<pre><code>{
  name: name
}
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>In v2 the model split <code>:name</code> into a <code>:first</code> and <code>:last</code> name and in v3 <code>:name</code> has finally been deprecated. A version v3 Person model would look as follows.</p>

<p>``` ruby
class Person
  include Mongoid::Document</p>

<p>  field :first
  field :last</p>

<p>  def as_json</p>

<pre><code>{
  first: first,
  last: last
}
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>How can we combine these two implementations and write <code>Person.find(params[:id]).as_json({ :version =&gt; ? })</code>?</p>

<p>In <a href="http://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> we've introduced a declarative way of versioning JSON. Here's the code for Person v3.</p>

<p>``` ruby
class Person
  include Mongoid::Document
  include Mongoid::CachedJson</p>

<p>  field :first
  field :last</p>

<p>  def name</p>

<pre><code>[ first, last ].join(" ")
</code></pre>

<p>  end</p>

<p>  json_fields \</p>

<pre><code>name: { :versions =&gt; [ :v1, :v2 ] },
first: { :versions =&gt; [ :v2, :v3 ] },
last: { :versions =&gt; [ :v2, :v3 ] }
</code></pre>

<p>end
```</p>

<p>With the <a href="http://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> gem you also get caching that respects JSON versioning, for free. Read about it <a href="http://artsy.github.com/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caching Model JSON with Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.com/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/"/>
    <updated>2012-02-20T13:06:00-05:00</updated>
    <id>http://artsy.github.com/blog/2012/02/20/caching-model-json-with-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Consider the following two <a href="http://mongoid.org">Mongoid</a> domain models, <em>Widget</em> and <em>Gadget</em>.</p>

<p>``` ruby widget.rb
class Widget
  include Mongoid::Document</p>

<p>  field :name
  has_many :gadgets
end
<code>
</code> ruby gadget.rb
class Gadget
  include Mongoid::Document</p>

<p>  field :name
  field :extras</p>

<p>  belongs_to :widget
end
```
And an API call that returns a collection of widgets.</p>

<p><code>ruby
get 'widgets' do
  Widget.all.as_json
end
</code></p>

<p>Given many widgets, the API makes a subquery to fetch the corresponding gadgets for each widget.</p>

<p>Introducing <a href="https://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a>. This library mitigates several frequent problems with such code.</p>

<ul>
<li>Adds a declarative way of specifying a subset of fields to be returned part of <em>as_json</em>.</li>
<li>Avoids a large amount of subqueries by caching document JSONs participating in the parent-child relationship.</li>
<li>Provides a consistent strategy for restricting child documents' fields from being returned via the parent JSON.</li>
</ul>


<p>Using <em>Mongoid::CachedJson</em> we were able to cut our JSON API average response time by about a factor of 10. Find it <a href="https://github.com/dblock/mongoid-cached-json">on Github</a>.</p>
]]></content>
  </entry>
  
</feed>
